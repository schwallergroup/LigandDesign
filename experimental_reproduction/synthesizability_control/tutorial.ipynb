{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Config JSON\n",
    "\n",
    "`Saturn` adapts the execution workflow of [REINVENT Version 3.2](https://github.com/MolecularAI/Reinvent). All parameters of the reinforcement learning run are specified using a `JSON` config.\n",
    "\n",
    "For the initial code release, this notebook is minimal and just walks through how to impose various reaction constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Reward Function\n",
    "\n",
    "Define the reward function to include all the properties to be optimized for.\n",
    "\n",
    "Below is the reward function for all Development experiments in the paper with the reward function composed of:\n",
    "\n",
    "1. QuickVina2-GPU docking against ClpP\n",
    "2. QED\n",
    "3. Number of hydrogen bond donors < 4\n",
    "4. Imposing various reaction constraints using [Syntheseus](https://github.com/microsoft/syntheseus/)\n",
    "\n",
    "Below, `<path to saturn>` refers to where the `saturn` codebase is cloned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each dictionary below defines a specific reward function component (for example, QED)\n",
    "# For a list of supported oracle components, see oracles/utils.py\n",
    "# Below are details on the key parameters:\n",
    "# \"weight\":weight of the oracle component - higher makes the reward contribution from the component more important\n",
    "# \"preliminary_check\": whether to run this specific oracle component first and if the reward does not pass a threshold, discard the SMILES. \n",
    "#                       This is useful for components that are computationally inexpensive as a way to \"pre-screen\" the batch and not waste oracle calls \n",
    "# \"reward_shaping_function_parameters\": reward shaping function to apply to the component. The syntax is exactly the same as REINVENT 3.2. \n",
    "#                                       See the following notebook for function visualizations: https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Score_Transformations.ipynb\n",
    "\n",
    "oracle_components = [\n",
    "    # QuickVina2-GPU docking\n",
    "    {\n",
    "        \"name\": \"quickvina2_gpu\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {\n",
    "            \"binary\": \"<path to the QuickVina2-GPU binary executable\",\n",
    "            \"force_field\": \"uff\",\n",
    "            \"receptor\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-2-monomers-pdbfixer.pdbqt\",\n",
    "            \"reference_ligand\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-reference.pdb\",\n",
    "            \"thread\": 8000,\n",
    "            \"results_dir\": \"<where to save docking results (poses and scores)\"\n",
    "        },\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"reverse_sigmoid\",\n",
    "            \"parameters\": {\n",
    "                \"low\": -16,\n",
    "                \"high\": 0,\n",
    "                \"k\": 0.15\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # QED\n",
    "    {\n",
    "        \"name\": \"qed\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"no_transformation\"\n",
    "        }\n",
    "    },\n",
    "    # Number of hydrogen bond donors\n",
    "    {\n",
    "        \"name\": \"num_hbd\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"step\",\n",
    "            \"parameters\": {\n",
    "                \"low\": 0,\n",
    "                \"high\": 3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main block of the notebook as all reaction constraints can be specified by the single dictionary below\n",
    "reaction_constraints_oracle = {\n",
    "    \"name\": \"syntheseus\",\n",
    "    \"weight\": 1,\n",
    "    \"preliminary_check\": False,\n",
    "    \"specific_parameters\": {\n",
    "        # This is the syntheseus conda environment\n",
    "        \"syntheseus_env_name\": \"syntheseus-full\",\n",
    "        \n",
    "         # This is the retrosynthesis model. All pre-print experiments were run with MEGAN \n",
    "         # but \"localretro\", \"retroknn\", \"rootaligned\", and \"graph2edits\" are also supported\n",
    "        \"reaction_model\": \"megan\",\n",
    "\n",
    "        # This is the path to the building blocks stock file\n",
    "        # The eMolecules stock used in the pre-print can be downloaded from: https://doi.org/10.6084/m9.figshare.29040977.v1\n",
    "        \"building_blocks_file\": \"<path to building blocks stock file>\", \n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------------------------------\n",
    "        # The block below concerns with enforcing specific building blocks, based on our TANGO pre-print: https://arxiv.org/abs/2410.11527\n",
    "        # This means that generated molecules will not only have a predicted synthesis route, but one of the building blocks in \n",
    "        # \"enforced_building_blocks_file\" will be present in the routes. \n",
    "        # WARNING: If using this option with your own building blocks, ensure that the \"building_blocks_file\" also contains the \n",
    "        #          \"enforced blocks\". This is important because otherwise, the retrosynthesis model cannot even propose the \n",
    "        #          \"enforced blocks\" and the reaction constraint would be impossible to satisfy\n",
    "        # -------------------------------------------------------------------------------------------------------------------------------\n",
    "        \"enforced_building_blocks\": {\n",
    "            # True if you want to enforce blocks\n",
    "            \"enforce_blocks\": False,\n",
    "\n",
    "            # This is the path to the file containing the enforced building blocks\n",
    "            # The enforced blocks used in the pre-print can be downloaded from: https://doi.org/10.6084/m9.figshare.29040977.v1\n",
    "            # They are a sub-set of the eMolecules stock\n",
    "            \"enforced_building_blocks_file\": \"<path to enforced building blocks stock file>\",\n",
    "\n",
    "            # True if you want to enforce the building blocks at the start of the route\n",
    "            # NOTE: This was not experimented with in the pre-print, but examples of this capability can be seen in the TANGO pre-print: https://arxiv.org/abs/2410.11527\n",
    "            \"enforce_start\": False,\n",
    "\n",
    "            # True if you want to use the TANGO reward to enforce building blocks (should be always True)\n",
    "            \"use_dense_reward\": True,\n",
    "\n",
    "            # These are the default parameters of TANGO\n",
    "            \"reward_type\": \"tango_fms\",\n",
    "            \"tango_weights\": {\n",
    "                \"tanimoto\": 0.5,\n",
    "                \"fg\": 0.5,\n",
    "                \"fms\": 0.5\n",
    "            }\n",
    "        },\n",
    "        # -------------------------------------------------------------------------------------------------------------------------------\n",
    "        # The block below concerns with enforcing specific building blocks, based on our TANGO pre-print: https://arxiv.org/abs/2410.11527\n",
    "        # This means that generated molecules will not only have a predicted synthesis route, but one of the building blocks in \n",
    "        # \"enforced_building_blocks_file\" will be present in the routes. \n",
    "        # WARNING: If using this option with your own building blocks, ensure that the \"building_blocks_file\" also contains the \n",
    "        #          \"enforced blocks\". This is important because otherwise, the retrosynthesis model cannot even propose the \n",
    "        #          \"enforced blocks\" and the reaction constraint would be impossible to satisfy\n",
    "        # -------------------------------------------------------------------------------------------------------------------------------\n",
    "        \"enforced_reactions\": {\n",
    "            # Must be True if wanting to enforce *any* reaction constraints\n",
    "            \"enforce_rxn_class_presence\": True,\n",
    "\n",
    "            # If True, *only* reactions listed in \"enforced_rxn_classes\" are permitted\n",
    "            # NOTE: This naturally implies all other reactions are avoided\n",
    "            \"enforce_all_reactions\": True,\n",
    "\n",
    "            # Rxn-INSIGHT conda environment name\n",
    "            \"rxn_insight_env_name\": \"rxn-insight\",\n",
    "\n",
    "            # True if you want to use NameRxn to label reactions instead of Rxn-INSIGHT\n",
    "            # NOTE: This requires a license from NextMove Software\n",
    "            \"use_namerxn\": False,\n",
    "            \"namerxn_binary_path\": \"<path to your namerxn binary executable>/HazELNut/namerxn\",\n",
    "\n",
    "            # List of reactions to enforce\n",
    "            # NOTE: Reaction matching is performed by string matching so be careful with typos (case-insensitive)\n",
    "            #       Reactions are matched if the reaction label contains the below strings. For example, \"to amide\" will match\n",
    "            #       any reaction with \"to amide\" in the label. For Rxn-INSIGHT reaction names, see https://github.com/schwallergroup/Rxn-INSIGHT/blob/master/src/rxn_insight/data/smirks.json\n",
    "            \"enforced_rxn_classes\": [\n",
    "                # Example: \"to amide\"\n",
    "                # Any amount of reactions can be listed here\n",
    "            ],\n",
    "\n",
    "            # List of reactions to avoid\n",
    "            # NOTE: If enforcing to avoid reactions (below) *and* also enforcing the presence of reactions (above),\n",
    "            #       Then satisfying the reaction constraint means satisfying both the presence and avoidance constraints\n",
    "            \"avoid_rxn_classes\": [\n",
    "                # Example: [\"protection\", \"deprotection\"]\n",
    "                # Any amount of reactions can be listed here\n",
    "            ],\n",
    "\n",
    "            # Path to the Rxn-INSIGHT extraction script - other than the saturn clone path, this does not need to be changed\n",
    "            \"rxn_insight_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_rxn_insight_info.py\",\n",
    "\n",
    "            # Path to the NameRxn extraction script - other than the saturn clone path, this does not need to be changed\n",
    "            \"namerxn_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_namerxn_info.py\",\n",
    "\n",
    "            # Whether to perform reaction-based enumeration to yield initial molecules already satisfying the reaction constraints\n",
    "            # NOTE: In our preliminary testing, this was not strictly beneficial in the case studies of the pre-print\n",
    "            \"seed_reactions\": False,\n",
    "            # Reaction \"seeding\" requires some pre-computed files. If seed_reactions is True, the pre-computed file will be checked\n",
    "            # If it does not exist, it will be automatically generated.\n",
    "            \"seed_reactions_file_folder\": \"dummy\"\n",
    "        },\n",
    "\n",
    "        # Helper script for extracting route data - other than the saturn clone path, this does not need to be changed\n",
    "        \"route_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_syntheseus_route_data.py\",\n",
    "\n",
    "        # Maximum time allowed for the retrosynthesis model\n",
    "        \"time_limit_s\": 180,\n",
    "\n",
    "        # True means to incentivize shorter routes\n",
    "        \"minimize_path_length\": False, \n",
    "\n",
    "        # Parallelization is not supported at the moment - in the future, multi-GPU/threading will be supported\n",
    "        \"parallelize\": False,  \n",
    "        \"max_workers\": 4,\n",
    "\n",
    "\n",
    "        \"results_dir\": \"<path to save raw syntheseus output (pickled data, rendered PDF routes, etc.)>\"\n",
    "    },\n",
    "    \"reward_shaping_function_parameters\": {\n",
    "        \"transformation_function\": \"no_transformation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add this oracle component to the list of reward components\n",
    "oracle_components.append(reaction_constraints_oracle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logging\": {\n",
    "        # How often to save out generated molecules and a model checkpoint - 5,000 denotes after every 5,000 oracle calls\n",
    "        \"logging_frequency\": 5000,\n",
    "        \"logging_path\": \"<path to save log file>\",\n",
    "        \"model_checkpoints_dir\": \"<path to directory to save model checkpoints>\"\n",
    "    },\n",
    "    \"oracle\": {\n",
    "        # Oracle budget\n",
    "        \"budget\": 15000,\n",
    "        # False denotes that generated molecules that have been generated before will have its reward retrieved from the cache which does not impose an oracle call\n",
    "        \"allow_oracle_repeats\": False,\n",
    "\n",
    "        # Weighted geometric mean to aggregate reward components\n",
    "        \"aggregator\": \"product\",\n",
    "\n",
    "        # This is the list of reward components defined in the cells above\n",
    "        \"components\": oracle_components\n",
    "    },\n",
    "    \"goal_directed_generation\": {\n",
    "        \"reinforcement_learning\": {\n",
    "            \"prior\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            \"agent\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            # These parameters affect sampling behaviour - default works\n",
    "            # See https://arxiv.org/abs/2405.17066 for more details\n",
    "            \"batch_size\": 64,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"sigma\": 128.0,\n",
    "            \"augmented_memory\": True,\n",
    "            \"augmentation_rounds\": 2,\n",
    "            \"selective_memory_purge\": True\n",
    "        },\n",
    "        # Hill-climbing experience replay adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0235-x\n",
    "        \"experience_replay\": {\n",
    "            \"memory_size\": 100,\n",
    "            \"sample_size\": 10,\n",
    "            \"smiles\": []\n",
    "        },\n",
    "        # Diversity filter adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00473-0\n",
    "        \"diversity_filter\": {\n",
    "            \"name\": \"IdenticalMurckoScaffold\",\n",
    "            \"bucket_size\": 10\n",
    "        },\n",
    "        # This block is for Hallucinated Memory: https://arxiv.org/abs/2405.17066 - details are omitted here\n",
    "        \"hallucinated_memory\": {\n",
    "            \"execute_hallucinated_memory\": False,\n",
    "            \"hallucination_method\": \"ga\",\n",
    "            \"num_hallucinations\": 100,\n",
    "            \"num_selected\": 5,\n",
    "            \"selection_criterion\": \"random\"\n",
    "        },\n",
    "        # This block is for Beam Enumeration: https://openreview.net/forum?id=7UhxsmbdaQ - details are omitted here\n",
    "        \"beam_enumeration\": {\n",
    "            \"execute_beam_enumeration\": False,\n",
    "            \"beam_k\": 2,\n",
    "            \"beam_steps\": 18,\n",
    "            \"substructure_type\": \"structure\",\n",
    "            \"structure_min_size\": 15,\n",
    "            \"pool_size\": 4,\n",
    "            \"pool_saving_frequency\": 1000,\n",
    "            \"patience\": 5,\n",
    "            \"token_sampling_method\": \"topk\",\n",
    "            \"filter_patience_limit\": 100000\n",
    "        }\n",
    "    },\n",
    "    # This block is for pre-training - details are omitted here\n",
    "    \"distribution_learning\": {\n",
    "        \"parameters\": {\n",
    "            \"agent\": \"<unused>\",\n",
    "            \"training_steps\": 20,\n",
    "            \"batch_size\": 512,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"training_dataset_path\": \"<path to training dataset>\",\n",
    "            \"train_with_randomization\": True,\n",
    "            \"transfer_learning\": False\n",
    "        }\n",
    "    },\n",
    "    # \"goal_directed_generation\" denotes a reinforcement learning run\n",
    "    \"running_mode\": \"goal_directed_generation\",\n",
    "    # The default model architecture is Mamba: https://arxiv.org/abs/2312.00752\n",
    "    \"model_architecture\": \"mamba\",\n",
    "    # CPU also works but it is *extremely* slow\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 0\n",
    "}\n",
    "\n",
    "CONFIG_SAVE_PATH = \"<path to save the config.json>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CONFIG_SAVE_PATH, f\"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Full Config JSONs\n",
    "\n",
    "The cells below produce two example configuration JSONs used in the pre-print.\n",
    "\n",
    "**NOTE**: The `saturn` clone path and save paths still needs to be specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enforce the presence of the Mitsunobu while avoiding protection/deprotection reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_components = [\n",
    "    # QuickVina2-GPU docking\n",
    "    {\n",
    "        \"name\": \"quickvina2_gpu\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {\n",
    "            \"binary\": \"<path to the QuickVina2-GPU binary executable\",\n",
    "            \"force_field\": \"uff\",\n",
    "            \"receptor\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-2-monomers-pdbfixer.pdbqt\",\n",
    "            \"reference_ligand\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-reference.pdb\",\n",
    "            \"thread\": 8000,\n",
    "            \"results_dir\": \"<where to save docking results (poses and scores)\"\n",
    "        },\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"reverse_sigmoid\",\n",
    "            \"parameters\": {\n",
    "                \"low\": -16,\n",
    "                \"high\": 0,\n",
    "                \"k\": 0.15\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # QED\n",
    "    {\n",
    "        \"name\": \"qed\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"no_transformation\"\n",
    "        }\n",
    "    },\n",
    "    # Number of hydrogen bond donors\n",
    "    {\n",
    "        \"name\": \"num_hbd\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"step\",\n",
    "            \"parameters\": {\n",
    "                \"low\": 0,\n",
    "                \"high\": 3\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Syntheseus\n",
    "    {\n",
    "    \"name\": \"syntheseus\",\n",
    "    \"weight\": 1,\n",
    "    \"preliminary_check\": False,\n",
    "    \"specific_parameters\": {\n",
    "        \"syntheseus_env_name\": \"syntheseus-full\",\n",
    "        \"reaction_model\": \"megan\",\n",
    "        \"building_blocks_file\": \"<path to building blocks stock file>\", \n",
    "        \"enforced_building_blocks\": {\n",
    "            \"enforce_blocks\": False,\n",
    "            \"enforced_building_blocks_file\": \"<path to enforced building blocks stock file>\",\n",
    "            \"enforce_start\": False,\n",
    "            \"use_dense_reward\": True,\n",
    "            \"reward_type\": \"tango_fms\",\n",
    "            \"tango_weights\": {\n",
    "                \"tanimoto\": 0.5,\n",
    "                \"fg\": 0.5,\n",
    "                \"fms\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"enforced_reactions\": {\n",
    "            \"enforce_rxn_class_presence\": True,\n",
    "            \"enforce_all_reactions\": False,\n",
    "            \"rxn_insight_env_name\": \"rxn-insight\",\n",
    "            \"use_namerxn\": False,\n",
    "            \"namerxn_binary_path\": \"<path to your namerxn binary executable>/HazELNut/namerxn\",\n",
    "            \"enforced_rxn_classes\": [\n",
    "                \"mitsunobu\"\n",
    "            ],\n",
    "            \"avoid_rxn_classes\": [\n",
    "                \"protection\", \n",
    "                \"deprotection\"\n",
    "            ],\n",
    "            \"rxn_insight_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_rxn_insight_info.py\",\n",
    "            \"namerxn_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_namerxn_info.py\",\n",
    "            \"seed_reactions\": False,\n",
    "            \"seed_reactions_file_folder\": \"dummy\"\n",
    "        },\n",
    "        \"route_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_syntheseus_route_data.py\",\n",
    "        \"time_limit_s\": 180,\n",
    "        \"minimize_path_length\": False, \n",
    "        \"parallelize\": False,  \n",
    "        \"max_workers\": 4,\n",
    "        \"results_dir\": \"<path to save raw syntheseus output (pickled data, rendered PDF routes, etc.)>\"\n",
    "    },\n",
    "    \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"no_transformation\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logging\": {\n",
    "        # How often to save out generated molecules and a model checkpoint - 5,000 denotes after every 5,000 oracle calls\n",
    "        \"logging_frequency\": 5000,\n",
    "        \"logging_path\": \"<path to save log file>\",\n",
    "        \"model_checkpoints_dir\": \"<path to directory to save model checkpoints>\"\n",
    "    },\n",
    "    \"oracle\": {\n",
    "        # Oracle budget\n",
    "        \"budget\": 15000,\n",
    "        # False denotes that generated molecules that have been generated before will have its reward retrieved from the cache which does not impose an oracle call\n",
    "        \"allow_oracle_repeats\": False,\n",
    "\n",
    "        # Weighted geometric mean to aggregate reward components\n",
    "        \"aggregator\": \"product\",\n",
    "\n",
    "        # This is the list of reward components defined in the cells above\n",
    "        \"components\": oracle_components\n",
    "    },\n",
    "    \"goal_directed_generation\": {\n",
    "        \"reinforcement_learning\": {\n",
    "            \"prior\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            \"agent\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            # These parameters affect sampling behaviour - default works\n",
    "            # See https://arxiv.org/abs/2405.17066 for more details\n",
    "            \"batch_size\": 64,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"sigma\": 128.0,\n",
    "            \"augmented_memory\": True,\n",
    "            \"augmentation_rounds\": 2,\n",
    "            \"selective_memory_purge\": True\n",
    "        },\n",
    "        # Hill-climbing experience replay adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0235-x\n",
    "        \"experience_replay\": {\n",
    "            \"memory_size\": 100,\n",
    "            \"sample_size\": 10,\n",
    "            \"smiles\": []\n",
    "        },\n",
    "        # Diversity filter adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00473-0\n",
    "        \"diversity_filter\": {\n",
    "            \"name\": \"IdenticalMurckoScaffold\",\n",
    "            \"bucket_size\": 10\n",
    "        },\n",
    "        # This block is for Hallucinated Memory: https://arxiv.org/abs/2405.17066 - details are omitted here\n",
    "        \"hallucinated_memory\": {\n",
    "            \"execute_hallucinated_memory\": False,\n",
    "            \"hallucination_method\": \"ga\",\n",
    "            \"num_hallucinations\": 100,\n",
    "            \"num_selected\": 5,\n",
    "            \"selection_criterion\": \"random\"\n",
    "        },\n",
    "        # This block is for Beam Enumeration: https://openreview.net/forum?id=7UhxsmbdaQ - details are omitted here\n",
    "        \"beam_enumeration\": {\n",
    "            \"execute_beam_enumeration\": False,\n",
    "            \"beam_k\": 2,\n",
    "            \"beam_steps\": 18,\n",
    "            \"substructure_type\": \"structure\",\n",
    "            \"structure_min_size\": 15,\n",
    "            \"pool_size\": 4,\n",
    "            \"pool_saving_frequency\": 1000,\n",
    "            \"patience\": 5,\n",
    "            \"token_sampling_method\": \"topk\",\n",
    "            \"filter_patience_limit\": 100000\n",
    "        }\n",
    "    },\n",
    "    # This block is for pre-training - details are omitted here\n",
    "    \"distribution_learning\": {\n",
    "        \"parameters\": {\n",
    "            \"agent\": \"<unused>\",\n",
    "            \"training_steps\": 20,\n",
    "            \"batch_size\": 512,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"training_dataset_path\": \"<path to training dataset>\",\n",
    "            \"train_with_randomization\": True,\n",
    "            \"transfer_learning\": False\n",
    "        }\n",
    "    },\n",
    "    # \"goal_directed_generation\" denotes a reinforcement learning run\n",
    "    \"running_mode\": \"goal_directed_generation\",\n",
    "    # The default model architecture is Mamba: https://arxiv.org/abs/2312.00752\n",
    "    \"model_architecture\": \"mamba\",\n",
    "    # CPU also works but it is *extremely* slow\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 0\n",
    "}\n",
    "\n",
    "CONFIG_SAVE_PATH = \"./enforce-mitsunobu-avoid-protection-deprotection.json\"\n",
    "with open(CONFIG_SAVE_PATH, \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enforce all amide reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_components = [\n",
    "    # QuickVina2-GPU docking\n",
    "    {\n",
    "        \"name\": \"quickvina2_gpu\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {\n",
    "            \"binary\": \"<path to the QuickVina2-GPU binary executable\",\n",
    "            \"force_field\": \"uff\",\n",
    "            \"receptor\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-2-monomers-pdbfixer.pdbqt\",\n",
    "            \"reference_ligand\": \"<path to saturn>/experimental_reproduction/synthesizability/7uvu-reference.pdb\",\n",
    "            \"thread\": 8000,\n",
    "            \"results_dir\": \"<where to save docking results (poses and scores)\"\n",
    "        },\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"reverse_sigmoid\",\n",
    "            \"parameters\": {\n",
    "                \"low\": -16,\n",
    "                \"high\": 0,\n",
    "                \"k\": 0.15\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # QED\n",
    "    {\n",
    "        \"name\": \"qed\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"no_transformation\"\n",
    "        }\n",
    "    },\n",
    "    # Number of hydrogen bond donors\n",
    "    {\n",
    "        \"name\": \"num_hbd\",\n",
    "        \"weight\": 1,\n",
    "        \"preliminary_check\": False,\n",
    "        \"specific_parameters\": {},\n",
    "        \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"step\",\n",
    "            \"parameters\": {\n",
    "                \"low\": 0,\n",
    "                \"high\": 3\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Syntheseus\n",
    "    {\n",
    "    \"name\": \"syntheseus\",\n",
    "    \"weight\": 1,\n",
    "    \"preliminary_check\": False,\n",
    "    \"specific_parameters\": {\n",
    "        \"syntheseus_env_name\": \"syntheseus-full\",\n",
    "        \"reaction_model\": \"megan\",\n",
    "        \"building_blocks_file\": \"<path to building blocks stock file>\", \n",
    "        \"enforced_building_blocks\": {\n",
    "            \"enforce_blocks\": False,\n",
    "            \"enforced_building_blocks_file\": \"<path to enforced building blocks stock file>\",\n",
    "            \"enforce_start\": False,\n",
    "            \"use_dense_reward\": True,\n",
    "            \"reward_type\": \"tango_fms\",\n",
    "            \"tango_weights\": {\n",
    "                \"tanimoto\": 0.5,\n",
    "                \"fg\": 0.5,\n",
    "                \"fms\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"enforced_reactions\": {\n",
    "            \"enforce_rxn_class_presence\": True,\n",
    "            \"enforce_all_reactions\": True,  # Enforce all reactions\n",
    "            \"rxn_insight_env_name\": \"rxn-insight\",\n",
    "            \"use_namerxn\": False,\n",
    "            \"namerxn_binary_path\": \"<path to your namerxn binary executable>/HazELNut/namerxn\",\n",
    "            \"enforced_rxn_classes\": [\n",
    "                \"to amide\"\n",
    "            ],\n",
    "            \"avoid_rxn_classes\": [],\n",
    "            \"rxn_insight_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_rxn_insight_info.py\",\n",
    "            \"namerxn_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_namerxn_info.py\",\n",
    "            \"seed_reactions\": False,\n",
    "            \"seed_reactions_file_folder\": \"dummy\"\n",
    "        },\n",
    "        \"route_extraction_script_path\": \"<path to saturn>/oracles/synthesizability/utils/extract_syntheseus_route_data.py\",\n",
    "        \"time_limit_s\": 180,\n",
    "        \"minimize_path_length\": False, \n",
    "        \"parallelize\": False,  \n",
    "        \"max_workers\": 4,\n",
    "        \"results_dir\": \"<path to save raw syntheseus output (pickled data, rendered PDF routes, etc.)>\"\n",
    "    },\n",
    "    \"reward_shaping_function_parameters\": {\n",
    "            \"transformation_function\": \"no_transformation\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logging\": {\n",
    "        # How often to save out generated molecules and a model checkpoint - 5,000 denotes after every 5,000 oracle calls\n",
    "        \"logging_frequency\": 5000,\n",
    "        \"logging_path\": \"<path to save log file>\",\n",
    "        \"model_checkpoints_dir\": \"<path to directory to save model checkpoints>\"\n",
    "    },\n",
    "    \"oracle\": {\n",
    "        # Oracle budget\n",
    "        \"budget\": 15000,\n",
    "        # False denotes that generated molecules that have been generated before will have its reward retrieved from the cache which does not impose an oracle call\n",
    "        \"allow_oracle_repeats\": False,\n",
    "\n",
    "        # Weighted geometric mean to aggregate reward components\n",
    "        \"aggregator\": \"product\",\n",
    "\n",
    "        # This is the list of reward components defined in the cells above\n",
    "        \"components\": oracle_components\n",
    "    },\n",
    "    \"goal_directed_generation\": {\n",
    "        \"reinforcement_learning\": {\n",
    "            \"prior\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            \"agent\": \"<path to saturn>/experimental_reproduction/checkpoint_models/pubchem_mamba_5_retrained.prior\",\n",
    "            # These parameters affect sampling behaviour - default works\n",
    "            # See https://arxiv.org/abs/2405.17066 for more details\n",
    "            \"batch_size\": 64,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"sigma\": 128.0,\n",
    "            \"augmented_memory\": True,\n",
    "            \"augmentation_rounds\": 2,\n",
    "            \"selective_memory_purge\": True\n",
    "        },\n",
    "        # Hill-climbing experience replay adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0235-x\n",
    "        \"experience_replay\": {\n",
    "            \"memory_size\": 100,\n",
    "            \"sample_size\": 10,\n",
    "            \"smiles\": []\n",
    "        },\n",
    "        # Diversity filter adapted from: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00473-0\n",
    "        \"diversity_filter\": {\n",
    "            \"name\": \"IdenticalMurckoScaffold\",\n",
    "            \"bucket_size\": 10\n",
    "        },\n",
    "        # This block is for Hallucinated Memory: https://arxiv.org/abs/2405.17066 - details are omitted here\n",
    "        \"hallucinated_memory\": {\n",
    "            \"execute_hallucinated_memory\": False,\n",
    "            \"hallucination_method\": \"ga\",\n",
    "            \"num_hallucinations\": 100,\n",
    "            \"num_selected\": 5,\n",
    "            \"selection_criterion\": \"random\"\n",
    "        },\n",
    "        # This block is for Beam Enumeration: https://openreview.net/forum?id=7UhxsmbdaQ - details are omitted here\n",
    "        \"beam_enumeration\": {\n",
    "            \"execute_beam_enumeration\": False,\n",
    "            \"beam_k\": 2,\n",
    "            \"beam_steps\": 18,\n",
    "            \"substructure_type\": \"structure\",\n",
    "            \"structure_min_size\": 15,\n",
    "            \"pool_size\": 4,\n",
    "            \"pool_saving_frequency\": 1000,\n",
    "            \"patience\": 5,\n",
    "            \"token_sampling_method\": \"topk\",\n",
    "            \"filter_patience_limit\": 100000\n",
    "        }\n",
    "    },\n",
    "    # This block is for pre-training - details are omitted here\n",
    "    \"distribution_learning\": {\n",
    "        \"parameters\": {\n",
    "            \"agent\": \"<unused>\",\n",
    "            \"training_steps\": 20,\n",
    "            \"batch_size\": 512,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"training_dataset_path\": \"<path to training dataset>\",\n",
    "            \"train_with_randomization\": True,\n",
    "            \"transfer_learning\": False\n",
    "        }\n",
    "    },\n",
    "    # \"goal_directed_generation\" denotes a reinforcement learning run\n",
    "    \"running_mode\": \"goal_directed_generation\",\n",
    "    # The default model architecture is Mamba: https://arxiv.org/abs/2312.00752\n",
    "    \"model_architecture\": \"mamba\",\n",
    "    # CPU also works but it is *extremely* slow\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 0\n",
    "}\n",
    "\n",
    "CONFIG_SAVE_PATH = \"./enforce-all-amide-reactions.json\"\n",
    "with open(CONFIG_SAVE_PATH, \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Files\n",
    "\n",
    "In the specified syntheseus results save directory, the raw syntheseus output is saved and tagged by the oracle calls. Other files are:\n",
    "\n",
    "1. `matched_generated_smiles_with_rxn.json` - contains all generated SMILES satisfying the reaction constraints\n",
    "\n",
    "2. `smiles_rxn_tracker` - contains synthesis route information for *all* generated SMILES so not necessarily only the ones that satisfy the reaction constraints. The information here is sufficient to reconstruct the synthesis routes  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rxn-insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
